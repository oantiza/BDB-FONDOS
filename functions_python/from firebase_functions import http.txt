from firebase_functions import https_fn, options
from firebase_admin import initialize_app, firestore
from datetime import datetime
import json

# Inicializaci√≥n b√°sica
initialize_app()

# ==========================================
# CONFIGURACI√ìN GLOBAL
# ==========================================
BENCHMARK_RF_ISIN = 'IE00B18GC888' 
BENCHMARK_RV_ISIN = 'IE00B03HCZ61'
EODHD_API_KEY = "692fd3daddba57.47682479" 
BUCKET_NAME = "bdb-fondos.firebasestorage.app" 
TRADING_DAYS = 252
RISK_FREE_RATE = 0.03

# CACH√â EN MEMORIA
PRICE_CACHE = {}

# Configuraci√≥n CORS Permisiva
cors_config = options.CorsOptions(cors_origins="*", cors_methods=["GET", "POST", "OPTIONS"])

# ==========================================
# 1. UTILIDADES
# ==========================================

def get_price_data(assets_list, db):
    # Importaci√≥n diferida (Lazy Import)
    import pandas as pd
    import numpy as np
    
    def generate_synthetic_series(days=1200, vol=0.12, ret=0.07, seed=None):
        if seed is not None: np.random.seed(seed)
        end_date = datetime.now()
        dates = pd.date_range(end=end_date, periods=days, freq='B')
        dt = 1/252
        mu = ret * dt
        sigma = vol * np.sqrt(dt)
        returns = np.random.normal(loc=mu, scale=sigma, size=days)
        price_path = 100 * (1 + returns).cumprod()
        return {d.strftime('%Y-%m-%d'): float(round(p, 2)) for d, p in zip(dates, price_path)}

    price_data = {}
    missing_assets = []

    # 1. REVISAR CACH√â RAM
    for isin in assets_list:
        if isin in PRICE_CACHE:
            price_data[isin] = PRICE_CACHE[isin]
        else:
            missing_assets.append(isin)
            
    if not missing_assets:
        print("‚ö° [CACHE HIT] Todos los activos recuperados de memoria RAM.")
        return price_data

    # 2. CONSULTAR FIRESTORE
    print(f"üì• [DB READ] Buscando {len(missing_assets)} activos en Firestore...")
    
    for i, isin in enumerate(missing_assets):
        loaded = False
        try:
            doc = db.collection('historico_vl_v2').document(isin).get()
            if doc.exists:
                data = doc.to_dict()
                series = data.get('series', [])
                if len(series) > 50:
                    clean_series = {}
                    for p in series:
                        if p.get('date') and p.get('price'):
                            d_val = p['date']
                            if hasattr(d_val, 'strftime'): d_str = d_val.strftime('%Y-%m-%d')
                            else: d_str = str(d_val).split('T')[0]
                            clean_series[d_str] = float(p['price'])
                    
                    if len(clean_series) > 50:
                        price_data[isin] = clean_series
                        PRICE_CACHE[isin] = clean_series 
                        loaded = True
        except Exception as e:
            print(f"‚ö†Ô∏è Error leyendo {isin}: {e}")

        if not loaded:
            print(f"‚ö†Ô∏è {isin}: Usando datos SINT√âTICOS.")
            fake_vol = 0.05 + (0.15 * (i % 4) / 3) 
            fake_ret = 0.04 + (0.06 * (i % 3) / 2)
            price_data[isin] = generate_synthetic_series(vol=fake_vol, ret=fake_ret, seed=i)

    return price_data

# ==========================================
# 2. ENDPOINTS
# ==========================================

@https_fn.on_call(region="europe-west1", memory=options.MemoryOption.GB_1, timeout_sec=60, cors=cors_config)
def getMarketIndex(request: https_fn.CallableRequest):
    import requests
    from datetime import datetime, timedelta
    
    try:
        symbol = request.data.get('symbol', 'GSPC.INDX')
        start_date = (datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d')
        url = f"https://eodhd.com/api/eod/{symbol}"
        params = {'api_token': EODHD_API_KEY, 'fmt': 'json', 'from': start_date, 'order': 'a'}
        
        r = requests.get(url, params=params, timeout=5)
        raw = r.json() if r.status_code == 200 else []
        
        series = []
        if isinstance(raw, list):
            for p in raw:
                if p.get('date') and p.get('close'):
                    series.append({'x': p['date'], 'y': float(p['close'])})
                    
        return {'series': series, 'symbol': symbol}
    except Exception as e:
        return {'error': str(e), 'series': []}

@https_fn.on_call(region="europe-west1", memory=options.MemoryOption.GB_1, timeout_sec=60, cors=cors_config)
def getYieldCurve(request: https_fn.CallableRequest):
    import requests
    try:
        region = request.data.get('region', 'US')
        
        if region == 'EU':
            tickers = {'2Y': 'DE2Y.GBOND', '5Y': 'DE5Y.GBOND', '10Y': 'DE10Y.GBOND'}
        else:
            tickers = {'3M': 'US3M.GBOND', '2Y': 'US2Y.GBOND', '5Y': 'US5Y.GBOND', '10Y': 'US10Y.GBOND', '30Y': 'US30Y.GBOND'}
            
        curve_data = []
        for label, ticker in tickers.items():
            url = f"https://eodhd.com/api/eod/{ticker}"
            params = {'api_token': EODHD_API_KEY, 'fmt': 'json', 'order': 'd', 'limit': 1}
            r = requests.get(url, params=params, timeout=3)
            yield_val = 0
            if r.status_code == 200:
                data = r.json()
                if isinstance(data, list) and len(data) > 0:
                    yield_val = float(data[0]['close'])
            curve_data.append({'maturity': label, 'yield': yield_val})
            
        return {'curve': curve_data, 'region': region}

    except Exception as e:
        print(f"Yield Error: {e}")
        return {'curve': [{'maturity': 'Error', 'yield': 0}], 'error': str(e)}

@https_fn.on_call(region="europe-west1", memory=options.MemoryOption.GB_2, timeout_sec=120, cors=cors_config)
def optimize_portfolio_quant(request: https_fn.CallableRequest):
    req_data = request.data
    
    if req_data.get('warmup') is True:
        return {'status': 'warmed_up'}

    try:
        import pandas as pd
        import numpy as np
        from pypfopt import EfficientFrontier, risk_models, expected_returns, objective_functions

        assets_list = req_data.get('assets', [])
        risk_level = req_data.get('risk_level', 5)
        
        if not assets_list: return {'status': 'error', 'warnings': ['Cartera vac√≠a']}
        
        db = firestore.client()
        price_data = get_price_data(assets_list, db)
        
        df = pd.DataFrame(price_data)
        df.index = pd.to_datetime(df.index)
        df = df.sort_index().fillna(method='ffill').fillna(method='bfill')
        
        mu = expected_returns.ema_historical_return(df, span=252)
        
        try:
            S = risk_models.CovarianceShrinkage(df).ledoit_wolf()
        except Exception as math_err:
            print(f"‚ö†Ô∏è Ledoit-Wolf fall√≥. Usando covarianza est√°ndar.")
            S = risk_models.sample_cov(df)
            S = risk_models.fix_nonpositive_semidefinite(S)
        
        n_assets = len(assets_list)
        RISK_VOL_MAP = {
            1: 0.02, 2: 0.04, 3: 0.055, 4: 0.075, 5: 0.10,
            6: 0.12, 7: 0.15, 8: 0.18, 9: 0.22, 10: 0.99
        }
        target_volatility = RISK_VOL_MAP.get(int(risk_level), 0.10)
        max_weight = max(0.40, (1.0 / n_assets) + 0.15) 
        
        ef = EfficientFrontier(mu, S)
        ef.add_objective(objective_functions.L2_reg, gamma=0.5) 
        ef.add_constraint(lambda w: w <= max_weight) 
        ef.add_constraint(lambda w: w >= 0.01) 
        
        try:
            weights = ef.efficient_risk(target_volatility)
        except:
            print("‚ö†Ô∏è Fall√≥ efficient_risk, usando max_sharpe")
            weights = ef.max_sharpe(risk_free_rate=RISK_FREE_RATE)

        clean_weights = ef.clean_weights()
        perf = ef.portfolio_performance(risk_free_rate=RISK_FREE_RATE)
        
        return { 
            'status': 'optimal', 
            'weights': clean_weights, 
            'metrics': {'return': perf[0], 'volatility': perf[1], 'sharpe': perf[2]} 
        }

    except Exception as e:
        print(f"‚ùå Error CR√çTICO Optimizaci√≥n: {e}")
        n = len(assets_list) if assets_list else 1
        import traceback
        traceback.print_exc()
        
        return {
            'status': 'fallback', 
            'weights': {isin: 1.0/n for isin in assets_list}, 
            'metrics': {'return': 0.05, 'volatility': 0.10, 'sharpe': 0.5},
            'warnings': [str(e)]
        }

@https_fn.on_call(region="europe-west1", memory=options.MemoryOption.GB_2, timeout_sec=120, cors=cors_config)
def backtest_portfolio(request: https_fn.CallableRequest):
    try:
        import pandas as pd
        import numpy as np

        data = request.data
        portfolio = data.get('portfolio', [])
        if not portfolio: return {'error': 'Cartera vac√≠a'}
        
        db = firestore.client()
        assets = [p['isin'] for p in portfolio]
        weights_map = {p['isin']: float(p['weight'])/100.0 for p in portfolio}
        all_assets = assets + [BENCHMARK_RF_ISIN, BENCHMARK_RV_ISIN]
        
        price_data = get_price_data(all_assets, db)
        df = pd.DataFrame(price_data)
        df.index = pd.to_datetime(df.index)
        df = df.sort_index().fillna(method='ffill').fillna(method='bfill')
        
        valid_assets = [c for c in df.columns if c in assets]
        if not valid_assets: raise Exception("Sin datos v√°lidos para backtest")
        
        df_port = df[valid_assets]
        returns = df_port.pct_change().dropna()
        w_vector = np.array([weights_map.get(c, 0) for c in df_port.columns])
        if w_vector.sum() > 0: w_vector = w_vector / w_vector.sum()
        
        port_ret = returns.dot(w_vector)
        cumulative = (1 + port_ret).cumprod() * 100
        
        days = len(cumulative)
        years = days / 252
        total_ret = cumulative.iloc[-1] / 100 - 1 if days > 0 else 0
        cagr = (1 + total_ret) ** (1/years) - 1 if years > 0 else 0
        vol = port_ret.std() * np.sqrt(252) if days > 0 else 0
        sharpe = (cagr - 0.03) / vol if vol > 0 else 0
        max_dd = ((cumulative - cumulative.cummax()) / cumulative.cummax()).min() if days > 0 else 0
        
        rf_curve = df[BENCHMARK_RF_ISIN] if BENCHMARK_RF_ISIN in df else pd.Series(np.linspace(100, 105, len(cumulative)), index=cumulative.index)
        rv_curve = df[BENCHMARK_RV_ISIN] if BENCHMARK_RV_ISIN in df else pd.Series(np.linspace(100, 130, len(cumulative)), index=cumulative.index)
        
        def normalize(ser): return (ser / ser.iloc[0] * 100) if len(ser) > 0 else ser
        def to_chart(ser): return [{'x': d.strftime('%Y-%m-%d'), 'y': round(v, 2)} for d, v in ser.items()]

        return {
            'portfolioSeries': to_chart(cumulative),
            'benchmarkSeries': {
                'conservative': to_chart(normalize(rf_curve)),
                'moderate': to_chart(normalize(rf_curve * 0.6 + rv_curve * 0.4)),
                'aggressive': to_chart(normalize(rv_curve))
            },
            'metrics': {'cagr': cagr, 'volatility': vol, 'sharpe': sharpe, 'maxDrawdown': max_dd},
            'correlationMatrix': returns.corr().round(2).fillna(0).values.tolist(),
            'synthetics': [
                {'name': 'Conservador', 'vol': 0.04, 'ret': 0.02},
                {'name': 'Moderado', 'vol': 0.08, 'ret': 0.05},
                {'name': 'Agresivo', 'vol': 0.15, 'ret': 0.09}
            ]
        }

    except Exception as e:
        print(f"‚ùå Error Backtest: {e}")
        import traceback
        traceback.print_exc()
        return {'error': str(e)}

@https_fn.on_call(region="europe-west1", memory=options.MemoryOption.GB_1, timeout_sec=60, cors=cors_config)
def getFinancialNews(request: https_fn.CallableRequest):
    import requests 
    try:
        data = request.data
        raw_query = data.get('query', 'general')
        mode = data.get('mode', 'general')
        
        TAG_MAP = {
            'general': 'balance',
            'inflation': 'inflation',
            'interest rates': 'interest rates',
            'gdp': 'gdp',
            'employment': 'employment',
            'earnings': 'earnings'
        }
        
        final_query = raw_query
        if mode == 'general' and raw_query in TAG_MAP:
            final_query = TAG_MAP[raw_query]

        url = "https://eodhd.com/api/news"
        params = {'api_token': EODHD_API_KEY, 'limit': 20, 'offset': 0}
        
        if mode == 'ticker':
            params['s'] = final_query 
        else:
            params['t'] = final_query 

        r = requests.get(url, params=params, timeout=10)
        news_list = r.json() if r.status_code == 200 else []
        
        if not isinstance(news_list, list): 
             news_list = [] 

        articles = []
        for item in news_list:
            if not item.get('title'): continue
            articles.append({
                'title': item.get('title'),
                'summary': item.get('content', '')[:250] + "...",
                'link': item.get('link'),
                'date': item.get('date'),
                'source': 'EOD Wire'
            })
            
        return {'articles': articles}

    except Exception as e:
        print(f"News Error: {e}")
        return {'articles': [], 'error': str(e)}